{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cafe_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rEdLl9exJ4zdP0OggidiIvONEJfLEfKG",
      "authorship_tag": "ABX9TyPa5abp1p6x1iUJCzPnmShx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KRiver28/prac/blob/master/Cafe_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3qpLx9geuvP",
        "outputId": "c7d03cfb-2067-4e29-ac56-40cf2072d734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BIGDATA_STUDY/project_NLP/transform_test\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/BIGDATA_STUDY/project_NLP/transform_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Transformer import *\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "gyJJesu-e39l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "########파일 불러오기(Q, A가 있는 csv형태여야함.)\n",
        "##################################\n",
        "\n",
        "#csv 파일 불러오기\n",
        "\n",
        "\n",
        "\n",
        "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/BIGDATA_STUDY/project_NLP/KoGPT2-chatbot-master/koGPT2_test/Chatbot_data/ChatbotData.csv')\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LYmSrIS8fgSZ",
        "outputId": "72a6c84f-135d-4b58-a1a8-cbe7ffdca0be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                        Q  \\\n",
              "0               0      빙수 위에 뿌려진 과일에서 쉰 냄새가 나는데 어떻게 하면 되죠?   \n",
              "1               1                  마카롱 주문했는데 마카롱이 엄청 딱딱해요.   \n",
              "2               2  와플 지금 받았는데 너무 눅눅해서 못먹겠어요 이거 어떻게 하면 되나요?   \n",
              "3               3       케이크에 생크림 모양이 너무 변형된 것 같은데 어떻게 하나요?   \n",
              "4               5                과일이 좀 씁쓸한데 이거 다 익은 거 맞나요?   \n",
              "...           ...                                      ...   \n",
              "35933        3727                                   얼마인가요?   \n",
              "35934        3728                                     얼마죠?   \n",
              "35935        3729                             메뉴랑 가격 알려주세요   \n",
              "35936        3730                                    메뉴 가격   \n",
              "35937        3731                                      메뉴판   \n",
              "\n",
              "                                                       A  label  \n",
              "0                              죄송합니다. 카운터에서 확인 도와드리겠습니다.     41  \n",
              "1                              죄송합니다. 카운터에서 확인 도와드리겠습니다.     41  \n",
              "2                              죄송합니다. 카운터에서 확인 도와드리겠습니다.     41  \n",
              "3                              죄송합니다. 카운터에서 확인 도와드리겠습니다.     41  \n",
              "4                              죄송합니다. 카운터에서 확인 도와드리겠습니다.     41  \n",
              "...                                                  ...    ...  \n",
              "35933                                      어떤 메뉴 말씀이신가요?     72  \n",
              "35934                                      어떤 메뉴 말씀이신가요?     72  \n",
              "35935  아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...     72  \n",
              "35936  아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...     72  \n",
              "35937  아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...     72  \n",
              "\n",
              "[35938 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-260a5e7d-13d1-40d2-b65d-7a9489261ac2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>빙수 위에 뿌려진 과일에서 쉰 냄새가 나는데 어떻게 하면 되죠?</td>\n",
              "      <td>죄송합니다. 카운터에서 확인 도와드리겠습니다.</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>마카롱 주문했는데 마카롱이 엄청 딱딱해요.</td>\n",
              "      <td>죄송합니다. 카운터에서 확인 도와드리겠습니다.</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>와플 지금 받았는데 너무 눅눅해서 못먹겠어요 이거 어떻게 하면 되나요?</td>\n",
              "      <td>죄송합니다. 카운터에서 확인 도와드리겠습니다.</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>케이크에 생크림 모양이 너무 변형된 것 같은데 어떻게 하나요?</td>\n",
              "      <td>죄송합니다. 카운터에서 확인 도와드리겠습니다.</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>과일이 좀 씁쓸한데 이거 다 익은 거 맞나요?</td>\n",
              "      <td>죄송합니다. 카운터에서 확인 도와드리겠습니다.</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35933</th>\n",
              "      <td>3727</td>\n",
              "      <td>얼마인가요?</td>\n",
              "      <td>어떤 메뉴 말씀이신가요?</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35934</th>\n",
              "      <td>3728</td>\n",
              "      <td>얼마죠?</td>\n",
              "      <td>어떤 메뉴 말씀이신가요?</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35935</th>\n",
              "      <td>3729</td>\n",
              "      <td>메뉴랑 가격 알려주세요</td>\n",
              "      <td>아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35936</th>\n",
              "      <td>3730</td>\n",
              "      <td>메뉴 가격</td>\n",
              "      <td>아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35937</th>\n",
              "      <td>3731</td>\n",
              "      <td>메뉴판</td>\n",
              "      <td>아메리카노: 3500원, 카페라떼: 4500원, 카페모카: 5500원, 바닐라라떼:...</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35938 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-260a5e7d-13d1-40d2-b65d-7a9489261ac2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-260a5e7d-13d1-40d2-b65d-7a9489261ac2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-260a5e7d-13d1-40d2-b65d-7a9489261ac2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################\n",
        "######전처리 작업\n",
        "######################\n",
        "\n",
        "questions = []\n",
        "for sentence in train_data['Q']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)\n",
        "\n",
        "\n",
        "answers = []\n",
        "for sentence in train_data['A']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    # ex) 12시 땡! -> 12시 땡 !\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)\n",
        "\n",
        "\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "\n",
        "\n",
        "\n",
        "# 최대 길이를 40으로 정의\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "\n",
        "\n",
        "\n",
        "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "R9PREQR8fgQB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "#########transformer 모델 만들기\n",
        "################################\n",
        "\n",
        "# 하이퍼파라미터\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    \n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZynqY6nfgOS",
        "outputId": "4196e070-10ce-4d25-bd75-b0f0e3a2251b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 7901, 256)\n",
            "(1, 7901, 256)\n",
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    3076864     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3604224     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 7901)   2030557     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,711,645\n",
            "Trainable params: 8,711,645\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습시키기\n",
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRpaYSE3fgLu",
        "outputId": "29a6b6af-d364-469f-a5c0-adacc2516cb0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "562/562 [==============================] - 76s 121ms/step - loss: 1.2930 - accuracy: 0.0663\n",
            "Epoch 2/50\n",
            "562/562 [==============================] - 68s 121ms/step - loss: 0.7202 - accuracy: 0.1132\n",
            "Epoch 3/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.5976 - accuracy: 0.1237\n",
            "Epoch 4/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.5050 - accuracy: 0.1314\n",
            "Epoch 5/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.4316 - accuracy: 0.1379\n",
            "Epoch 6/50\n",
            "562/562 [==============================] - 68s 121ms/step - loss: 0.3715 - accuracy: 0.1435\n",
            "Epoch 7/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.3233 - accuracy: 0.1486\n",
            "Epoch 8/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.2814 - accuracy: 0.1537\n",
            "Epoch 9/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.2314 - accuracy: 0.1610\n",
            "Epoch 10/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.1889 - accuracy: 0.1680\n",
            "Epoch 11/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.1558 - accuracy: 0.1746\n",
            "Epoch 12/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.1301 - accuracy: 0.1798\n",
            "Epoch 13/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.1102 - accuracy: 0.1842\n",
            "Epoch 14/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0937 - accuracy: 0.1876\n",
            "Epoch 15/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0806 - accuracy: 0.1906\n",
            "Epoch 16/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.0708 - accuracy: 0.1929\n",
            "Epoch 17/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.0622 - accuracy: 0.1950\n",
            "Epoch 18/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.0550 - accuracy: 0.1967\n",
            "Epoch 19/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0496 - accuracy: 0.1982\n",
            "Epoch 20/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.0447 - accuracy: 0.1994\n",
            "Epoch 21/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0411 - accuracy: 0.2005\n",
            "Epoch 22/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0382 - accuracy: 0.2012\n",
            "Epoch 23/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0349 - accuracy: 0.2021\n",
            "Epoch 24/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0328 - accuracy: 0.2027\n",
            "Epoch 25/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0305 - accuracy: 0.2033\n",
            "Epoch 26/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.0287 - accuracy: 0.2038\n",
            "Epoch 27/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.0270 - accuracy: 0.2043\n",
            "Epoch 28/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0252 - accuracy: 0.2047\n",
            "Epoch 29/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0239 - accuracy: 0.2052\n",
            "Epoch 30/50\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.0225 - accuracy: 0.2056\n",
            "Epoch 31/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0216 - accuracy: 0.2058\n",
            "Epoch 32/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0207 - accuracy: 0.2061\n",
            "Epoch 33/50\n",
            "562/562 [==============================] - 68s 121ms/step - loss: 0.0200 - accuracy: 0.2063\n",
            "Epoch 34/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0189 - accuracy: 0.2066\n",
            "Epoch 35/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0180 - accuracy: 0.2068\n",
            "Epoch 36/50\n",
            "562/562 [==============================] - 67s 118ms/step - loss: 0.0175 - accuracy: 0.2070\n",
            "Epoch 37/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0166 - accuracy: 0.2072\n",
            "Epoch 38/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0163 - accuracy: 0.2073\n",
            "Epoch 39/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0156 - accuracy: 0.2075\n",
            "Epoch 40/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0151 - accuracy: 0.2077\n",
            "Epoch 41/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0145 - accuracy: 0.2079\n",
            "Epoch 42/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0143 - accuracy: 0.2079\n",
            "Epoch 43/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0137 - accuracy: 0.2080\n",
            "Epoch 44/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0132 - accuracy: 0.2082\n",
            "Epoch 45/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0132 - accuracy: 0.2082\n",
            "Epoch 46/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0127 - accuracy: 0.2084\n",
            "Epoch 47/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0125 - accuracy: 0.2085\n",
            "Epoch 48/50\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.0121 - accuracy: 0.2085\n",
            "Epoch 49/50\n",
            "562/562 [==============================] - 67s 119ms/step - loss: 0.0120 - accuracy: 0.2086\n",
            "Epoch 50/50\n",
            "562/562 [==============================] - 70s 124ms/step - loss: 0.0119 - accuracy: 0.2086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fbd95cb90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########인풋, 아웃풋으로 구현해보기\n",
        "def preprocess_sentence(sentence):\n",
        "  # 단어와 구두점 사이에 공백 추가.\n",
        "  # ex) 12시 땡! -> 12시 땡 !\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "def evaluate(sentence):\n",
        "  # 입력 문장에 대한 전처리\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 예측 시작\n",
        "  try:\n",
        "      for i in range(MAX_LENGTH):\n",
        "        predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "        # 현재 시점의 예측 단어를 받아온다.\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "          break\n",
        "\n",
        "       # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
        "       # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "      # 단어 예측이 모두 끝났다면 output을 리턴.\n",
        "      return tf.squeeze(output, axis=0)\n",
        "  except:\n",
        "    print(\"죄송합니다.\")\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
        "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "\n",
        "  # print('Input: {}'.format(sentence))\n",
        "  # print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "\n",
        "def chatting(n=100):\n",
        "    for i in range(n):\n",
        "        question = input('Q : ')\n",
        "        \n",
        "        if  question == 'quit':\n",
        "            break\n",
        "        \n",
        "        print('A :', predict(question) )"
      ],
      "metadata": {
        "id": "sWJl0jq1fgId"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ########인풋, 아웃풋으로 구현해보기\n",
        "# def preprocess_sentence(sentence):\n",
        "#   # 단어와 구두점 사이에 공백 추가.\n",
        "#   # ex) 12시 땡! -> 12시 땡 !\n",
        "#   sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "#   sentence = sentence.strip()\n",
        "#   return sentence\n",
        "\n",
        "# def evaluate(sentence):\n",
        "#   # 입력 문장에 대한 전처리\n",
        "#   sentence = preprocess_sentence(sentence)\n",
        "\n",
        "#   # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
        "#   sentence = tf.expand_dims(\n",
        "#       START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "#   output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "#   # 디코더의 예측 시작\n",
        "  \n",
        "#   for i in range(MAX_LENGTH):\n",
        "#     predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "#     # 현재 시점의 예측 단어를 받아온다.\n",
        "#     predictions = predictions[:, -1:, :]\n",
        "#     predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "#     # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
        "#     if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "#       break\n",
        "\n",
        "#     # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
        "#     # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
        "#     output = tf.concat([output, predicted_id], axis=-1)\n",
        "#     if i== MAX_LENGTH:\n",
        "#       output = \"죄송합니다\"\n",
        "#       break\n",
        "#   # 단어 예측이 모두 끝났다면 output을 리턴.\n",
        "#   return tf.squeeze(output, axis=0)\n",
        "\n",
        "# def predict(sentence):\n",
        "#   prediction = evaluate(sentence)\n",
        "\n",
        "#   # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
        "#   # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
        "#   predicted_sentence = tokenizer.decode(\n",
        "#       [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "\n",
        "#   # print('Input: {}'.format(sentence))\n",
        "#   # print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "#   return predicted_sentence\n",
        "\n",
        "# def chatting(n=100):\n",
        "#     for i in range(n):\n",
        "#         question = input('Q : ')\n",
        "        \n",
        "#         if  question == 'quit':\n",
        "#             break\n",
        "        \n",
        "#         print('A :', predict(question) )"
      ],
      "metadata": {
        "id": "0m0FNN44aMA3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('transformer_model.h5')"
      ],
      "metadata": {
        "id": "QzywcSXZi4wK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### Chatting 시작 #######\n",
        "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
        "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
        "# 채팅을 시작한다.\n",
        "chatting(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vio89tifgDg",
        "outputId": "58d2b4bd-fff1-4711-f850-1bd6b1af5f1b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seq2Seq ChatBot (ver. 1.0)\n",
            "Chatting 모듈을 로드하고 있습니다 ...\n",
            "Q : 안녕하세요\n",
            "A : 어서오세요 ,  Learning Crew Café 입니다 .  무엇을 도와드릴까요 ?\n",
            "Q : 먹을것도 파나요?\n",
            "A : 빙수 ,  케이크 ,  쿠키 ,  아이스크림 ,  초콜릿 ,  와플 ,  도넛 ,  마카롱도 판매중입니다 .\n",
            "Q : 메뉴\n",
            "A : 네\n",
            "Q : 메뉴알려주세요\n",
            "A : 시즌 메뉴입니다\n",
            "Q : 메뉴는 뭐가 있나요?\n",
            "A : 커피도 있고 디저트도 있고 여러가지 있습니다\n",
            "Q : 음료 메뉴는 뭐가 있나요?\n",
            "A : 음료 메뉴는 아메리카노 ,  카페라떼 ,  카페모카 ,  바닐라라떼 ,  콜드브루 ,  카라멜 마끼아또 ,  카푸치노 ,  밀크티가 있습니다 .\n",
            "Q : 마실 것 뭐가 있나요?\n",
            "A : 음료 메뉴는 아메리카노 ,  카페라떼 ,  카페모카 ,  바닐라라떼 ,  콜드브루 ,  카라멜 마끼아또 ,  카푸치노 ,  밀크티가 있습니다 .\n",
            "Q : 메뉴 가격\n",
            "A : 블루베리 확인 되셨던 카드 주시면 \n",
            "Q : 메뉴랑 가격 알려주세요\n",
            "A : 곱게 갈은 냅니다\n",
            "Q : 메뉴판\n",
            "A : 천천히 보세요\n",
            "Q : 저기요\n",
            "A : 어서오세요 ,  Learning Crew Café 입니다 .  무엇을 도와드릴까요 ?\n",
            "Q : 아아 한잔 주세요\n",
            "A : 네 ,  아이스 아메리카노 한 잔 준비해드리겠습니다 .\n",
            "Q : 카페라떼 3잔이랑 도넛 같이 주문하면 얼마인가요?\n",
            "A : 총 15700원 입니다 .\n",
            "Q : 카페라떼 3잔이랑 카푸치노 2잔 주문하면 얼마인가요?\n",
            "A : 총 23500원 입니다 .\n",
            "Q : 카페라떼 3잔이랑 카푸치노 5잔 주문하면 얼마인가요?\n",
            "A : 총 38500원 입니다 .\n",
            "Q : 안녕하세요\n",
            "A : 어서오세요 ,  Learning Crew Café 입니다 .  무엇을 도와드릴까요 ?\n",
            "Q : 빙수 주세요\n",
            "A : 네\n",
            "Q : 빙수 얼마에요?\n",
            "A : 빙수 가격은 9800원 입니다 .\n",
            "Q : 캐리어에 담아주세요\n",
            "A : 네 알겠습니다 .\n",
            "Q : 아메리카노 2잔, 카페라떼 1잔이요\n",
            "A : 네 알겠습니다 .\n",
            "Q : 배고파요\n",
            "A : 딸기라떼 주세요\n",
            "Q : 뭐하세요\n",
            "A : 샌드위치 두종류있어요\n",
            "Q : 아아 주세요\n",
            "A : 네 ,  아이스 아메리카노 한 잔 준비해드리겠습니다 .\n",
            "Q : 아아 2잔주세요\n",
            "A : 네 알겠습니다\n",
            "Q : 아메리카노 주세요\n",
            "A : 차가운 것으로 드릴까요 ?  ,  따뜻한 것으로 드릴까요 ?\n",
            "Q : 따뜻한 카페라떼 2잔 주세요\n",
            "A : 따뜻한 카페라떼 2잔 \n",
            "Q : 아이스 라떼 한잔이요\n",
            "A : 네 될 예정이예요\n",
            "Q : 포장해주세요\n",
            "A : 네 포장해드리겠습니다 .\n",
            "Q : 벌레가 나왔어요\n",
            "A : 죄송합니다 .  카운터에서 확인 도와드리겠습니다 .\n",
            "Q : 아메리카노에 샷추가 해주세요\n",
            "A : 샷 추가 해드리겠습니다 .\n",
            "Q : 휘핑크림 얹어주세요\n",
            "A : 네\n",
            "Q : 아메리카노에 휘핑추가요\n",
            "A : 네\n",
            "Q : 휘핑크림 추가 얼마죠?\n",
            "A : 구성 관련 요청은 카운터에 문의 바랍니다 .\n",
            "Q : 샷추가 얼마죠?\n",
            "A : 샷 추가 1회 500원 입니다 .\n",
            "Q : 수고하셨습니다\n",
            "A : 그럼요 해도해도 끝이없는게 공부잖아요\n",
            "Q : 공부해요\n",
            "A : 그럼요 해도해도 끝이없는게 공부잖아요\n",
            "Q : 와이파이 비밀번호가 뭔가요?\n",
            "A : 죄송합니다 .  카운터에서 확인 도와드리겠습니다 .\n",
            "Q : 얼마죠\n",
            "A : 어떤 메뉴 말씀이신가요 ?\n",
            "Q : quit\n"
          ]
        }
      ]
    }
  ]
}